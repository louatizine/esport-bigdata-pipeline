# Esports Big Data Pipeline - Project Structure

## ğŸ¯ Active Components

### Core Pipeline
```
Riot Games API â†’ Kafka â†’ Spark â†’ Parquet Files â†’ Streamlit Dashboard
```

### Directory Structure

```
â”œâ”€â”€ README.md                          # Main documentation
â”œâ”€â”€ ARCHITECTURE.md                     # System architecture
â”œâ”€â”€ MONGODB_ATLAS_SETUP.md             # MongoDB Atlas setup guide
â”œâ”€â”€ PHASE2.md - PHASE5.md              # Phase implementation guides
â”œâ”€â”€ .env                               # Environment configuration
â”œâ”€â”€ docker-compose.yml                 # Docker services configuration
â”‚
â”œâ”€â”€ conf/                              # Configuration files
â”‚   â”œâ”€â”€ logging.yaml                   # Logging configuration
â”‚   â””â”€â”€ kafka/
â”‚       â””â”€â”€ topics.yaml                # Kafka topic definitions
â”‚
â”œâ”€â”€ data/                              # Data storage
â”‚   â”œâ”€â”€ bronze/                        # Raw data (unused currently)
â”‚   â”œâ”€â”€ silver/                        # Processed data (unused currently)
â”‚   â”œâ”€â”€ gold/                          # Analytics data (unused currently)
â”‚   â”œâ”€â”€ checkpoints/                   # Spark streaming checkpoints
â”‚   â””â”€â”€ processed/                     # Parquet output from Spark
â”‚       â””â”€â”€ matches/                   # Match data storage
â”‚
â”œâ”€â”€ requirements/                      # Python dependencies
â”‚   â”œâ”€â”€ ingestion.txt                  # Kafka + Riot API
â”‚   â”œâ”€â”€ spark.txt                      # PySpark
â”‚   â”œâ”€â”€ storage.txt                    # MongoDB
â”‚   â””â”€â”€ visualization.txt              # Streamlit
â”‚
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ create_topics.py               # Create Kafka topics
â”‚   â”œâ”€â”€ create_topics.sh               # Kafka topics shell script
â”‚   â”œâ”€â”€ test_kafka_producer.py         # Kafka producer test
â”‚   â””â”€â”€ run_spark_streaming.sh         # Spark streaming launcher
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ common/                        # Shared utilities
â”‚   â”‚   â”œâ”€â”€ logging_config.py          # Logging setup
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                     # Data ingestion
â”‚   â”‚   â”œâ”€â”€ kafka_config.py            # Kafka configuration
â”‚   â”‚   â”œâ”€â”€ riot_producer.py           # Riot API â†’ Kafka producer
â”‚   â”‚   â”œâ”€â”€ validate_ingestion.py      # Ingestion validation
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ storage/                       # Data storage
â”‚       â”œâ”€â”€ mongodb_atlas_loader.py    # MongoDB Atlas loader
â”‚       â”œâ”€â”€ storage_main.py            # Storage orchestrator
â”‚       â””â”€â”€ mongodb/
â”‚           â”œâ”€â”€ load_documents.py      # Document loader
â”‚           â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ spark/                             # Spark processing
â”‚   â”œâ”€â”€ main.py                        # Streaming orchestrator
â”‚   â”œâ”€â”€ analytics_main.py              # Analytics orchestrator
â”‚   â”œâ”€â”€ validate_analytics.py          # Analytics validation
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                       # Data schemas
â”‚   â”‚   â”œâ”€â”€ match_schema.py
â”‚   â”‚   â””â”€â”€ player_schema.py
â”‚   â”‚
â”‚   â”œâ”€â”€ streaming/                     # Streaming jobs
â”‚   â”‚   â”œâ”€â”€ match_stream.py            # Match streaming processor
â”‚   â”‚   â””â”€â”€ player_stream.py           # Player streaming processor
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                     # Analytics jobs
â”‚   â”‚   â”œâ”€â”€ match_analytics.py         # Match analytics
â”‚   â”‚   â”œâ”€â”€ player_analytics.py        # Player analytics
â”‚   â”‚   â””â”€â”€ ranking_analytics.py       # Ranking analytics
â”‚   â”‚
â”‚   â””â”€â”€ utils/                         # Spark utilities
â”‚       â”œâ”€â”€ spark_session.py           # Spark session factory
â”‚       â”œâ”€â”€ logger.py                  # Logging utilities
â”‚       â””â”€â”€ metrics.py                 # Metrics utilities
â”‚
â””â”€â”€ streamlit_kafka_dashboard.py      # ğŸ¨ Real-time dashboard (Kafka â†’ UI)
```

## ğŸš€ Active Services

1. **Kafka** (localhost:9092)
   - Event streaming platform
   - Topics: esport-matches, esport-players, esport-rankings

2. **Zookeeper** (localhost:2181)
   - Kafka coordination service

3. **Kafka-UI** (localhost:8090)
   - Web interface for Kafka monitoring

4. **Streamlit Dashboard** (localhost:8502)
   - Real-time data visualization
   - Reads directly from Kafka

## ğŸ“Š Data Flow

1. **Ingestion**: `python src/ingestion/riot_producer.py`
   - Fetches matches from Riot Games API
   - Publishes to Kafka topic: esport-matches

2. **Processing**: `python spark/main.py --job matches`
   - Consumes from Kafka
   - Transforms data
   - Writes to Parquet files

3. **Visualization**: `streamlit run streamlit_kafka_dashboard.py`
   - Reads from Kafka
   - Displays real-time analytics

## ğŸ”§ Key Files

- **.env**: Environment variables (API keys, database URIs)
- **docker-compose.yml**: Infrastructure services
- **riot_producer.py**: Real data ingestion
- **match_stream.py**: Spark streaming logic
- **streamlit_kafka_dashboard.py**: Dashboard application

## ğŸ“ Notes

- MongoDB Atlas integration code exists but SSL connection issues in devcontainer
- Processed data stored in Parquet format at `data/processed/matches/`
- Spark analytics modules exist but schema mismatch with Riot API data
